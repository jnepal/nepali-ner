{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Reimplementation of bam2014named\n",
    "    Nepali NER using SVM\n",
    "    \n",
    "    Author - Oyesh Mann Singh\n",
    "    Date - 05/24/2019\n",
    "    \n",
    "    Reimplementation on server\n",
    "    Date - 05/31/2019\n",
    "'''\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.svm as svm\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To convert the dataset into kaggle format. Just for ease!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set='umbc'\n",
    "\n",
    "data_root_path='../data/ner/bal/'\n",
    "if data_set == 'umbc':\n",
    "    data_root_path='../data/ner/combined/after_stemming/'\n",
    "\n",
    "datapath=data_root_path+'total.txt'\n",
    "outpath=data_root_path+'total_kaggle.txt'\n",
    "\n",
    "def kaggle_converter(datapath, outpath):\n",
    "    with open(datapath, 'r', encoding='utf-8') as in_file, open(outpath, 'w', encoding='utf-8') as out_file:\n",
    "        reader = csv.reader(in_file, delimiter=' ',  quoting=csv.QUOTE_NONE)\n",
    "        sent_counter=1\n",
    "        for i, row in enumerate(reader):\n",
    "            if len(row)>0:\n",
    "                out_file.write(str(sent_counter)+' '+row[0]+' '+row[1]+' '+row[2]+'\\n')\n",
    "            else:\n",
    "                sent_counter+=1\n",
    "                out_file.write('\\n')\n",
    "\n",
    "        in_file.close()\n",
    "        out_file.close()\n",
    "    \n",
    "# If you need to convert the data into kaggle format, then unlock the below function\n",
    "# Kaggle Format: <SENTENCE NO> <WORD> <POS_TAG> <ENTITY_TAG>\n",
    "# kaggle_converter(datapath, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>WORDS</th>\n",
       "      <th>TAGS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>वकिल</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>साहेव</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ले</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>यत्ति</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>भन्न</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SENTENCE  WORDS TAGS\n",
       "0         1   वकिल    O\n",
       "1         1  साहेव    O\n",
       "2         1     ले    O\n",
       "3         1  यत्ति    O\n",
       "4         1   भन्न    O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(outpath, sep=' ', encoding='utf-8', names=['SENTENCE','WORDS', 'POS', 'TAGS'], quoting=csv.QUOTE_NONE)\n",
    "\n",
    "# Drop POS, since we are not going to use it for this experiment\n",
    "df = df.drop(columns=['POS'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique sentences =  3606\n",
      "Total unique WORDS =  12473\n",
      "Total unique TAGS =  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique sentences = \", df.SENTENCE.nunique())\n",
    "print(\"Total unique WORDS = \", df.WORDS.nunique())\n",
    "print(\"Total unique TAGS = \", df.TAGS.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TAGS</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOC</td>\n",
       "      <td>2313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O</td>\n",
       "      <td>82775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORG</td>\n",
       "      <td>3811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PER</td>\n",
       "      <td>5059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TAGS  counts\n",
       "0  LOC    2313\n",
       "1    O   82775\n",
       "2  ORG    3811\n",
       "3  PER    5059"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('TAGS').size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12473 unique word\n"
     ]
    }
   ],
   "source": [
    "# Read the corpus\n",
    "corpus_path=data_root_path+'text_tag_only/text_only.txt'\n",
    "with open(corpus_path, 'r', encoding='utf-8') as in_file:\n",
    "    corpus = in_file.read().split()\n",
    "\n",
    "vocab=sorted(set(corpus))\n",
    "print ('{} unique word'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "word2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2word = np.array(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read gazeetteer list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaz_path='../data/ner/NER_surya/Archive/Final_gazetteer/'\n",
    "ent_path='../data/ner/NER_surya/Archive/Final_dictionary/'\n",
    "\n",
    "with open(gaz_path+'Action verb.txt', 'r', encoding='utf-8-sig') as in_file:\n",
    "    verb_list=in_file.read().strip().split()\n",
    "    in_file.close()\n",
    "    \n",
    "with open(gaz_path+'Common location word.txt', 'r', encoding='utf-8-sig') as in_file:\n",
    "    comm_loc_list=in_file.read().strip().split()\n",
    "    in_file.close()\n",
    "    \n",
    "with open(gaz_path+'Day name.txt', 'r', encoding='utf-8-sig') as in_file:\n",
    "    day_list=in_file.read().strip().split()\n",
    "    in_file.close()\n",
    "    \n",
    "with open(gaz_path+'Designation words.txt', 'r', encoding='utf-8-sig') as in_file:\n",
    "    desig_list=in_file.read().strip().split()\n",
    "    in_file.close()\n",
    "    \n",
    "with open(gaz_path+'Middle name.txt', 'r', encoding='utf-8-sig') as in_file:\n",
    "    mid_name_list=in_file.read().strip().split()\n",
    "    in_file.close()\n",
    "    \n",
    "with open(gaz_path+'Month name.txt', 'r', encoding='utf-8-sig') as in_file:\n",
    "    month_name_list=in_file.read().strip().split()\n",
    "    in_file.close()\n",
    "    \n",
    "with open(gaz_path+'Organization suffix word.txt', 'r', encoding='utf-8-sig') as in_file:\n",
    "    org_suff_list=in_file.read().strip().split()\n",
    "    in_file.close()\n",
    "    \n",
    "with open(gaz_path+'Person prefix word.txt', 'r', encoding='utf-8-sig') as in_file:\n",
    "    per_prefix_list=in_file.read().strip().split()\n",
    "    in_file.close()\n",
    "    \n",
    "with open(gaz_path+'Surname.txt', 'r', encoding='utf-8-sig') as in_file:\n",
    "    surname_list=in_file.read().strip().split()\n",
    "    in_file.close()\n",
    "    \n",
    "with open(ent_path+'1_person.txt', 'r', encoding='utf-8-sig') as in_file:\n",
    "    per_list=in_file.read().strip().split()\n",
    "    in_file.close()\n",
    "    \n",
    "with open(ent_path+'2_location.txt', 'r', encoding='utf-8-sig') as in_file:\n",
    "    loc_list=in_file.read().strip().split()\n",
    "    in_file.close()\n",
    "    \n",
    "with open(ent_path+'3_organization.txt', 'r', encoding='utf-8-sig') as in_file:\n",
    "    org_list=in_file.read().strip().split()\n",
    "    in_file.close()\n",
    "    \n",
    "with open(ent_path+'4_misc.txt', 'r', encoding='utf-8-sig') as in_file:\n",
    "    misc_list=in_file.read().strip().split()\n",
    "    in_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s['WORDS'].values.tolist(),\n",
    "                                                           s['TAGS'].values.tolist())]\n",
    "        self.grouped = self.data.groupby('SENTENCE').apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_next(self):\n",
    "        try: \n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s \n",
    "        except:\n",
    "            return None\n",
    "\n",
    "getter = SentenceGetter(df)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isdigitandcomma(word):\n",
    "    if word.count(',') > 0:\n",
    "        return ''.join(word.split(',')).isdigit()\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def isdigitandhyphen(word):\n",
    "    if word.count('-') > 0:\n",
    "        return ''.join(word.split('-')).isdigit()\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def isdigitandpercentage(word):\n",
    "    if word.count('%') > 0:\n",
    "        return ''.join(word.split('%')).isdigit()\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def isdigitandslash(word):\n",
    "    if word.count('/') > 0:\n",
    "        return ''.join(word.split('/')).isdigit()\n",
    "    elif word.count('\\\\') > 0:\n",
    "        return ''.join(word.split('\\\\')).isdigit()\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Assign features for every word\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    \n",
    "    features = {\n",
    "        'word': word2idx[word],\n",
    "        'BOS': True if i == 0 else False,\n",
    "        'word.length()': True if len(word) < 2 else False,\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word.isfourdigit()': True if word.isdigit() and len(word) == 4 else False,\n",
    "        'word.istwodigit()': True if word.isdigit() and len(word) == 2 else False,\n",
    "        'word.isdigitandcomma()': True if word.count(',') > 0 and ''.join(word.split(',')).isdigit() else False,\n",
    "        'word.isdigitandslash()': isdigitandslash(word),\n",
    "        'word.isdigitandhyphen()': isdigitandhyphen(word),\n",
    "        'word.isdigitandpercentage()': isdigitandpercentage(word),\n",
    "        'gaz.isperson()': True if word in per_list else False,\n",
    "        'gaz.isloc()': True if word in loc_list else False,\n",
    "        'gaz.isorg()': True if word in org_list else False,\n",
    "        'gaz.ismonth()': True if word in month_name_list else False,\n",
    "        'gaz.isday()': True if word in day_list else False,\n",
    "        'gaz.isperprefix()': True if word in per_prefix_list else False,    \n",
    "        'gaz.ismidname()': True if word in mid_name_list else False,\n",
    "        'gaz.issurname()': True if word in surname_list else False,\n",
    "        'gaz.iscommlocword()': True if word in comm_loc_list else False,\n",
    "        'gaz.isverb()': True if word in verb_list else False,\n",
    "        'gaz.isdesignation()': True if word in desig_list else False,\n",
    "        'gaz.isorgsuffix()': True if word in org_suff_list else False,        \n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features for every word\n",
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the X and y list, since we are not going to care about the context\n",
    "flat_X = [item for sublist in X for item in sublist]\n",
    "flat_y = [item for sublist in y for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 9993,\n",
       " 'BOS': True,\n",
       " 'word.length()': False,\n",
       " 'word.isdigit()': False,\n",
       " 'word.isfourdigit()': False,\n",
       " 'word.istwodigit()': False,\n",
       " 'word.isdigitandcomma()': False,\n",
       " 'word.isdigitandslash()': False,\n",
       " 'word.isdigitandhyphen()': False,\n",
       " 'word.isdigitandpercentage()': False,\n",
       " 'gaz.isperson()': False,\n",
       " 'gaz.isloc()': False,\n",
       " 'gaz.isorg()': False,\n",
       " 'gaz.ismonth()': False,\n",
       " 'gaz.isday()': False,\n",
       " 'gaz.isperprefix()': False,\n",
       " 'gaz.ismidname()': False,\n",
       " 'gaz.issurname()': False,\n",
       " 'gaz.iscommlocword()': False,\n",
       " 'gaz.isverb()': False,\n",
       " 'gaz.isdesignation()': True,\n",
       " 'gaz.isorgsuffix()': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOS</th>\n",
       "      <th>gaz.iscommlocword()</th>\n",
       "      <th>gaz.isday()</th>\n",
       "      <th>gaz.isdesignation()</th>\n",
       "      <th>gaz.isloc()</th>\n",
       "      <th>gaz.ismidname()</th>\n",
       "      <th>gaz.ismonth()</th>\n",
       "      <th>gaz.isorg()</th>\n",
       "      <th>gaz.isorgsuffix()</th>\n",
       "      <th>gaz.isperprefix()</th>\n",
       "      <th>...</th>\n",
       "      <th>gaz.isverb()</th>\n",
       "      <th>word</th>\n",
       "      <th>word.isdigit()</th>\n",
       "      <th>word.isdigitandcomma()</th>\n",
       "      <th>word.isdigitandhyphen()</th>\n",
       "      <th>word.isdigitandpercentage()</th>\n",
       "      <th>word.isdigitandslash()</th>\n",
       "      <th>word.isfourdigit()</th>\n",
       "      <th>word.istwodigit()</th>\n",
       "      <th>word.length()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9993.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11518.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9891.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9048.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8079.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BOS  gaz.iscommlocword()  gaz.isday()  gaz.isdesignation()  gaz.isloc()  \\\n",
       "0  1.0                  0.0          0.0                  1.0          0.0   \n",
       "1  0.0                  0.0          0.0                  0.0          0.0   \n",
       "2  0.0                  0.0          0.0                  0.0          0.0   \n",
       "3  0.0                  0.0          0.0                  0.0          0.0   \n",
       "4  0.0                  0.0          0.0                  0.0          0.0   \n",
       "\n",
       "   gaz.ismidname()  gaz.ismonth()  gaz.isorg()  gaz.isorgsuffix()  \\\n",
       "0              0.0            0.0          0.0                0.0   \n",
       "1              0.0            0.0          0.0                0.0   \n",
       "2              0.0            0.0          0.0                0.0   \n",
       "3              0.0            0.0          0.0                0.0   \n",
       "4              0.0            0.0          0.0                0.0   \n",
       "\n",
       "   gaz.isperprefix()      ...        gaz.isverb()     word  word.isdigit()  \\\n",
       "0                0.0      ...                 0.0   9993.0             0.0   \n",
       "1                0.0      ...                 0.0  11518.0             0.0   \n",
       "2                0.0      ...                 0.0   9891.0             0.0   \n",
       "3                0.0      ...                 0.0   9048.0             0.0   \n",
       "4                0.0      ...                 0.0   8079.0             0.0   \n",
       "\n",
       "   word.isdigitandcomma()  word.isdigitandhyphen()  \\\n",
       "0                     0.0                      0.0   \n",
       "1                     0.0                      0.0   \n",
       "2                     0.0                      0.0   \n",
       "3                     0.0                      0.0   \n",
       "4                     0.0                      0.0   \n",
       "\n",
       "   word.isdigitandpercentage()  word.isdigitandslash()  word.isfourdigit()  \\\n",
       "0                          0.0                     0.0                 0.0   \n",
       "1                          0.0                     0.0                 0.0   \n",
       "2                          0.0                     0.0                 0.0   \n",
       "3                          0.0                     0.0                 0.0   \n",
       "4                          0.0                     0.0                 0.0   \n",
       "\n",
       "   word.istwodigit()  word.length()  \n",
       "0                0.0            0.0  \n",
       "1                0.0            0.0  \n",
       "2                0.0            0.0  \n",
       "3                0.0            0.0  \n",
       "4                0.0            0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "v = DictVectorizer(sparse=False)\n",
    "X_vec = v.fit_transform(flat_X)\n",
    "\n",
    "vec_df = pd.DataFrame.from_dict(X_vec, orient='columns')\n",
    "vec_df.columns = v.feature_names_\n",
    "\n",
    "vec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, flat_y, test_size=0.33, random_state=163)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BOS',\n",
       " 'gaz.iscommlocword()',\n",
       " 'gaz.isday()',\n",
       " 'gaz.isdesignation()',\n",
       " 'gaz.isloc()',\n",
       " 'gaz.ismidname()',\n",
       " 'gaz.ismonth()',\n",
       " 'gaz.isorg()',\n",
       " 'gaz.isorgsuffix()',\n",
       " 'gaz.isperprefix()',\n",
       " 'gaz.isperson()',\n",
       " 'gaz.issurname()',\n",
       " 'gaz.isverb()',\n",
       " 'word',\n",
       " 'word.isdigit()',\n",
       " 'word.isdigitandcomma()',\n",
       " 'word.isdigitandhyphen()',\n",
       " 'word.isdigitandpercentage()',\n",
       " 'word.isdigitandslash()',\n",
       " 'word.isfourdigit()',\n",
       " 'word.istwodigit()',\n",
       " 'word.length()']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svec = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 4s, sys: 300 ms, total: 6min 4s\n",
      "Wall time: 6min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svec.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_path='../data/models/'\n",
    "model_file=model_path+'svm_ner_models.pkl'\n",
    "\n",
    "pickle.dump(svec, open(model_file, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "svec=pickle.load(open(model_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svec.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LOC', 'ORG', 'PER']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.TAGS.values\n",
    "\n",
    "classes = np.unique(y)\n",
    "classes = classes.tolist()\n",
    "new_classes = classes.copy()\n",
    "if data_set == 'bal':\n",
    "    new_classes.pop(2)        # To remove 'O' tag\n",
    "else:\n",
    "    new_classes.pop(1)        # To remove 'O' tag\n",
    "new_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9375302351082013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        LOC     0.7574    0.5553    0.6407       742\n",
      "        ORG     0.7826    0.5131    0.6198      1263\n",
      "        PER     0.8314    0.6107    0.7041      1631\n",
      "\n",
      "avg / total     0.7993    0.5655    0.6619      3636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, labels=new_classes, target_names=new_classes, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write results to file for conll evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file():\n",
    "    output_file='../data/ner/results/ner_svm_umbc.txt'\n",
    "    X_test_list=[]\n",
    "    for each in X_test:\n",
    "        X_test_list.append(idx2word[int(each[13])])    \n",
    "    y_test_list = y_test.tolist()\n",
    "    y_pred_list = y_pred.tolist()\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for x,y,z in zip(X_test_list, y_test_list, y_pred_list):\n",
    "            f.write(x+' '+y+' '+z+'\\n')\n",
    "            \n",
    "write_to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
