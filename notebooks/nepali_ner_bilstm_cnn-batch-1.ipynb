{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oyashi/miniconda3/lib/python3.7/site-packages/tqdm/std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Nepali NER for PERSON, ORGANIZATION, LOCATION\n",
    "    \n",
    "    Nepali BiLSTM CNN\n",
    "    \n",
    "    Author - Oyesh Mann Singh\n",
    "    Data - 05/03/2019\n",
    "'''\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(142)\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import vocab\n",
    "from torchtext import datasets\n",
    "from torchtext.datasets import SequenceTaggingDataset\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "tqdm.pandas(desc='Progress')\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import conll_eval as e\n",
    "import sys, unicodedata\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import csv\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# txt_field = data.Field(tokenize=list, use_vocab=True, init_token='<init>', eos_token='<eos>')\n",
    "# label_field = data.Field(unk_token=None, init_token='<init>', eos_token='<eos>')\n",
    "\n",
    "def split_into_char(x):\n",
    "    return x.split()\n",
    "\n",
    "txt_field = data.Field(tokenize=list, use_vocab=True)\n",
    "pos_field = data.Field(unk_token=None)\n",
    "label_field = data.Field(unk_token=None)\n",
    "char_field = data.Field(unk_token='<unk>', sequential=False)\n",
    "graph_field = data.Field(unk_token='<unk>', sequential=False)\n",
    "\n",
    "fields = (('TEXT', txt_field),('POS', pos_field),('TAG', label_field))\n",
    "\n",
    "# root_path='../data/ner/nepaliner/after_stemming/'\n",
    "root_path='../data/ner/ilprl/'\n",
    "\n",
    "train_ds, val_ds, test_ds = SequenceTaggingDataset.splits(path=root_path,\n",
    "                                                 fields=fields,\n",
    "                                                 separator=' ',\n",
    "                                                 train='train.txt', validation='val.txt', test='test.txt')\n",
    "\n",
    "nep2vec = '../data/nep2vec/'\n",
    "nep2glove='../data/glove'\n",
    "nep2ft='../data/fasttext/'\n",
    "\n",
    "# vec = vocab.Vectors(name='nep2vec_clean', cache=nep2vec)\n",
    "# vec = vocab.Vectors(name='nep2glove-stem.txt', cache=nep2glove)\n",
    "vec = vocab.Vectors(name='nep2ft.vec', cache=nep2ft)\n",
    "\n",
    "txt_field.build_vocab(train_ds, test_ds, val_ds, max_size=None, vectors=vec)\n",
    "label_field.build_vocab(train_ds.TAG, test_ds.TAG, val_ds.TAG)\n",
    "pos_field.build_vocab(train_ds.POS, test_ds.POS, val_ds.POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text vocab =  3254\n",
      "Length of NER label vocab =  6\n",
      "Length of POS vocab =  57\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(txt_field.vocab)):\n",
    "#     print(txt_field.vocab.itos[i])\n",
    "\n",
    "print('Length of text vocab = ',len(txt_field.vocab))\n",
    "print('Length of NER label vocab = ',len(label_field.vocab))\n",
    "print('Length of POS vocab = ',len(pos_field.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_list = []\n",
    "# for each in train_ds.examples + test_ds.examples + val_ds.examples:\n",
    "#     for x in each.TEXT:\n",
    "#         char_list+=list(x)\n",
    "# char_list = list(set(char_list))\n",
    "\n",
    "# char_list.sort()\n",
    "\n",
    "# print(char_list)\n",
    "\n",
    "# char_field.build_vocab(char_list)\n",
    "# char_vocab_length = len(char_field.vocab)\n",
    "# print(len(char_field.vocab))\n",
    "# print(len(char_list))\n",
    "\n",
    "# with open(root_path+'characters.txt', 'w', encoding='utf-8') as f:\n",
    "#     for item in char_list:\n",
    "#         f.write(item+' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read character level file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"', \"'\", '(', ')', ',', '-', '.', '/', ':', ';', '?', '[', 'ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श', 'ष', 'स', 'ह', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'े', 'ै', 'ो', 'ौ', '्', '।', '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', '\\u200c', '\\u200d', '–']\n",
      "Length of character vocab =  85\n"
     ]
    }
   ],
   "source": [
    "with open(root_path+'characters.txt', 'r', encoding='utf-8') as f:\n",
    "    char_list = f.read().strip().split()\n",
    "    print(char_list)\n",
    "    \n",
    "char_field.build_vocab(char_list)\n",
    "char_vocab_length = len(char_field.vocab)\n",
    "print('Length of character vocab = ',len(char_field.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a file full of grapheme cluster and just read those\n",
    "# from uniseg.graphemecluster import grapheme_clusters\n",
    "# graph_list = []\n",
    "# for each in train_ds.examples + test_ds.examples + val_ds.examples:\n",
    "#     for x in each.TEXT:\n",
    "#         graph_list+=list(grapheme_clusters(x))\n",
    "# graph_list = list(set(graph_list))\n",
    "# graph_list.sort()\n",
    "\n",
    "# graph_field.build_vocab(graph_list)\n",
    "# print(len(graph_field.vocab))\n",
    "# graph_vocab_length = len(graph_field.vocab)\n",
    "# # for i in range(0, len(graph_field.vocab)):\n",
    "# #     print(i, graph_field.vocab.itos[i])\n",
    "\n",
    "# with open(root_path+'grapheme.txt', 'w', encoding='utf-8') as f:\n",
    "#     for item in graph_list:\n",
    "#         f.write(item+' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read grapheme level file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"', \"'\", '(', ')', ',', '-', '.', '/', ':', ';', '?', '[', 'अ', 'अं', 'अ\\u200dं', 'आ', 'आँ', 'आं', 'इ', 'इँ', 'ई', 'उ', 'उँ', 'ऊ', 'ऊं', 'ऋ', 'ए', 'एँ', 'ऐ', 'ओ', 'औ', 'क', 'का', 'काँ', 'कां', 'कि', 'की', 'कु', 'कू', 'कृ', 'के', 'कै', 'को', 'कौ', 'क्', 'ख', 'खा', 'खि', 'खी', 'खु', 'खू', 'खे', 'खो', 'खौं', 'ख्', 'ख्\\u200d', 'ग', 'गं', 'गा', 'गाँ', 'गि', 'गी', 'गु', 'गृ', 'गे', 'गै', 'गो', 'गौ', 'ग्', 'घ', 'घा', 'घि', 'घी', 'घु', 'घृ', 'घे', 'घो', 'घ्', 'ङ', 'ङ्', 'ङ्\\u200d', 'च', 'चँ', 'चा', 'चाँ', 'चां', 'चि', 'ची', 'चु', 'चुँ', 'चू', 'चे', 'चै', 'चो', 'चौ', 'चौं', 'च्', 'छ', 'छा', 'छि', 'छी', 'छु', 'छे', 'छै', 'छो', 'छौ', 'छौं', 'ज', 'जा', 'जाँ', 'जां', 'जि', 'जी', 'जु', 'जू', 'जे', 'जै', 'जो', 'ज्', 'झ', 'झा', 'झि', 'झी', 'झू', 'झे', 'झै', 'झैं', 'झो', 'झों', 'झौ', 'झ्', 'ञ', 'ञा', 'ञे', 'ञ्', 'ञ्\\u200d', 'ट', 'टं', 'टा', 'टाँ', 'टि', 'टी', 'टु', 'टे', 'टें', 'टै', 'टो', 'ट्', 'ठ', 'ठा', 'ठि', 'ठी', 'ठू', 'ठे', 'ठो', 'ठ्', 'ड', 'डा', 'डाँ', 'डि', 'डी', 'डु', 'डे', 'डै', 'डो', 'डौ', 'डौं', 'ड्', 'ढ', 'ढं', 'ढा', 'ढि', 'ढी', 'ढो', 'ढ्', 'ण', 'णा', 'णि', 'णी', 'णु', 'ण्', 'त', 'तँ', 'तः', 'ता', 'तां', 'ति', 'ती', 'तु', 'तृ', 'ते', 'तै', 'तो', 'तौ', 'तौं', 'त्', 'त्\\u200d', 'थ', 'था', 'थि', 'थी', 'थु', 'थू', 'थे', 'थै', 'थो', 'थ्', 'द', 'दा', 'दाँ', 'दि', 'दिं', 'दी', 'दु', 'दुः', 'दू', 'दृ', 'दे', 'दै', 'दो', 'दौ', 'द्', 'द्\\u200d', 'ध', 'धा', 'धि', 'धी', 'धु', 'धू', 'धे', 'धै', 'धैं', 'धो', 'ध्', 'न', 'नं', 'नं\\u200c', 'नः', 'ना', 'नि', 'निः', 'नी', 'नु', 'नू', 'नृ', 'ने', 'नै', 'नो', 'नौ', 'नौं', 'न्', 'न्\\u200d', 'प', 'पं', 'पा', 'पाँ', 'पि', 'पी', 'पु', 'पू', 'पूं', 'पृ', 'पे', 'पै', 'पो', 'पौ', 'प्', 'प्\\u200d', 'फ', 'फा', 'फि', 'फी', 'फु', 'फू', 'फे', 'फै', 'फैं', 'फो', 'फ्', 'फ्\\u200c', 'ब', 'बं', 'बा', 'बाँ', 'बां', 'बि', 'बी', 'बु', 'बुँ', 'बृ', 'बे', 'बै', 'बैं', 'बो', 'बौ', 'ब्', 'भ', 'भा', 'भि', 'भी', 'भु', 'भू', 'भे', 'भै', 'भो', 'भौ', 'भ्', 'म', 'मं', 'मा', 'माँ', 'मां', 'मि', 'मी', 'मु', 'मू', 'मृ', 'मे', 'मै', 'मो', 'मौ', 'म्', 'य', 'यं', 'यः', 'या', 'याँ', 'यां', 'यि', 'यी', 'यु', 'यू', 'ये', 'यो', 'यौ', 'यौं', 'र', 'रं', 'रा', 'रां', 'रि', 'री', 'रु', 'रू', 'रूं', 'रे', 'रै', 'रो', 'रौ', 'रौं', 'रौं\\u200c', 'र्', 'र्\\u200d', 'ल', 'ला', 'लि', 'लिं', 'ली', 'लु', 'ले', 'लै', 'लो', 'लौ', 'ल्', 'व', 'वं', 'वा', 'वि', 'वी', 'वु', 'वृ', 'वे', 'वै', 'वो', 'व्', 'श', 'शं', 'शः', 'शा', 'शि', 'शिं', 'शी', 'शु', 'शू', 'शे', 'शो', 'श्', 'श्\\u200d', 'ष', 'षः', 'षा', 'षि', 'षी', 'षे', 'षो', 'ष्', 'ष्\\u200d', 'स', 'सँ', 'सं', 'सा', 'साँ', 'सां', 'सि', 'सिं', 'सी', 'सु', 'सू', 'सृ', 'से', 'सै', 'सैं', 'सै\\u200d', 'सो', 'सौ', 'स्', 'स\\u200d', 'ह', 'हँ', 'हं', 'हा', 'हाँ', 'हि', 'हिं', 'ही', 'हीँ', 'हीं', 'हु', 'हुँ', 'हृ', 'हे', 'है', 'हो', 'ह्', '।', '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', '–']\n",
      "Length of grapheme vocab =  463\n"
     ]
    }
   ],
   "source": [
    "# Create a file full of grapheme cluster and just read those\n",
    "from uniseg.graphemecluster import grapheme_clusters\n",
    "with open(root_path+'grapheme.txt', 'r', encoding='utf-8') as f:\n",
    "    graph_list = f.read().strip().split()\n",
    "    print(graph_list)\n",
    "    \n",
    "graph_list += char_list\n",
    "graph_list = set(graph_list)\n",
    "    \n",
    "graph_field.build_vocab(graph_list)\n",
    "graph_vocab_length = len(graph_field.vocab)\n",
    "print('Length of grapheme vocab = ',len(graph_field.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To verify the batch data\n",
    "def idxtosent(batch, idx):\n",
    "    '''\n",
    "        Returns the corresponding TEXT of given batch and index\n",
    "    '''      \n",
    "    return ' '.join([txt_field.vocab.itos[i] for i in batch.TEXT[idx].cpu().data.numpy()])\n",
    "\n",
    "\n",
    "def idxtotag(batch, idx):\n",
    "    '''\n",
    "        Returns the corresponding TAG of given batch and index\n",
    "    '''     \n",
    "    return ' '.join([label_field.vocab.itos[i] for i in batch.TAG[idx].cpu().data.numpy()])\n",
    "\n",
    "\n",
    "def tensortosent(tense):\n",
    "    '''\n",
    "        Returns the corresponding TEXT of given tensor\n",
    "    '''     \n",
    "    return ' '.join([txt_field.vocab.itos[i] for i in tense.cpu().data.numpy()])\n",
    "\n",
    "def tensortopos(tense):\n",
    "    '''\n",
    "        Returns the corresponding TEXT of given tensor\n",
    "    '''     \n",
    "    return ' '.join([pos_field.vocab.itos[i] for i in tense.cpu().data.numpy()])\n",
    "\n",
    "def tensortotag(tense):\n",
    "    '''\n",
    "        Returns the corresponding TEXT of given tensor\n",
    "    '''     \n",
    "    return ' '.join([label_field.vocab.itos[i] for i in tense.cpu().data.numpy()])\n",
    "\n",
    "def tensorToOneHot(tense):\n",
    "    '''\n",
    "        Returns the corresponding TEXT of given tensor\n",
    "    '''\n",
    "    try:\n",
    "        return pos_one_hot[tense.cpu().data.numpy()]\n",
    "    except ValueError:\n",
    "        return pos_one_host[-1]\n",
    "\n",
    "\n",
    "def NumpyToSent(tensor):\n",
    "    '''\n",
    "        Returns the corresponding TEXT of given Predictions\n",
    "        Returns chunks of string\n",
    "    '''    \n",
    "    return ' '.join([txt_field.vocab.itos[i[0]] for i in tensor.cpu().data.numpy()]).split()\n",
    "\n",
    "\n",
    "def PredToTag(predictions):\n",
    "    '''\n",
    "        Returns the corresponding TAGS of given Predictions\n",
    "        Returns chunks of string\n",
    "    '''\n",
    "    return ' '.join([label_field.vocab.itos[i] for i in predictions]).split()\n",
    "\n",
    "# Because len(pos) = 56 and len(pos_field.vocab) = 55\n",
    "n_values=len(pos_field.vocab)+2\n",
    "pos_one_hot = np.eye(n_values)\n",
    "one_hot_weight = torch.from_numpy(pos_one_hot).float()\n",
    "\n",
    "class BatchGenerator:\n",
    "    def __init__(self, dl, x_field, y_field, z_field):\n",
    "        self.dl, self.x_field, self.y_field, self.z_field = dl, x_field, y_field, z_field\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            X = getattr(batch, self.x_field)\n",
    "            y = getattr(batch, self.y_field)\n",
    "            z = getattr(batch, self.z_field)\n",
    "            yield ((X,y), z)\n",
    "\n",
    "def plot_loss(train_loss, val_loss, title):\n",
    "    plt.figure(figsize=[8,5])\n",
    "    plt.plot(train_loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.legend(['Training loss', 'Validation loss'])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def save_checkpoint(model, opt, train_loss, train_acc, val_loss, val_acc, filename, epochs):\n",
    "    save_parameters = {'model': model,\n",
    "                       'state_dict':model.state_dict(),\n",
    "                       'opt':opt,\n",
    "                       'opt_state': opt.state_dict(),\n",
    "                      'train_loss' : train_loss,\n",
    "                      'train_acc' : train_acc,\n",
    "                      'val_loss' : val_loss,\n",
    "                      'val_acc' : val_acc,\n",
    "                      'epochs' : epochs}\n",
    "    torch.save(save_parameters, filename)\n",
    "    \n",
    "    \n",
    "def load_checkpoint(filename):\n",
    "    checkpoint = torch.load(filename)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    opt = checkpoint['opt']\n",
    "    opt.load_state_dict(checkpoint['opt_state'])\n",
    "    train_loss = checkpoint['train_loss']\n",
    "    train_acc = checkpoint['train_acc']\n",
    "    val_loss = checkpoint['val_loss']\n",
    "    val_acc = checkpoint['val_acc']\n",
    "    epochs = checkpoint['epochs']\n",
    "    \n",
    "    return model, opt, train_loss, train_acc, val_loss, val_acc, epochs\n",
    "\n",
    "def fit(model, train_dl, val_dl, loss_fn, opt, start_epoch, lstm_model_file, epochs=1):\n",
    "    total_train_loss = []\n",
    "    total_train_acc = []\n",
    "    total_val_loss = []\n",
    "    total_val_acc = []\n",
    "    num_batch = len(train_dl)\n",
    "    prev_lstm_val_acc=0.0\n",
    "    prev_val_loss=100.0\n",
    "    counter=0\n",
    "    patience_limit=10\n",
    "    for epoch in tnrange(start_epoch, epochs):      \n",
    "        z_true_train = list()\n",
    "        z_pred_train = list()\n",
    "        total_loss_train = 0          \n",
    "        \n",
    "        t = tqdm_notebook(iter(train_dl), leave=False, total=num_batch)\n",
    "        for ((X,y),z) in t:\n",
    "            t.set_description(f'Epoch {epoch+1}')\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            pred = model(X, y)\n",
    "            \n",
    "            z = z.reshape(z.shape[0]*z.shape[1])\n",
    "            loss = loss_fn(pred, z)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            t.set_postfix(loss=loss.item())\n",
    "            pred_idx = torch.max(pred, dim=1)[1]\n",
    "\n",
    "            \n",
    "            z_true_train += list(z.cpu().data.numpy())\n",
    "            z_pred_train += list(pred_idx.cpu().data.numpy())\n",
    "            total_loss_train += loss.item()\n",
    "\n",
    "        train_acc = accuracy_score(z_true_train, z_pred_train)\n",
    "        train_loss = total_loss_train/len(train_dl)\n",
    "        total_train_loss.append(train_loss)\n",
    "        total_train_acc.append(train_acc)\n",
    "        \n",
    "        if val_dl:\n",
    "            z_true_val = list()\n",
    "            z_pred_val = list()\n",
    "            total_loss_val = 0\n",
    "            for ((X,y),z) in tqdm_notebook(iter(val_dl), leave=False):\n",
    "                pred = model(X, y)\n",
    "                z = z.reshape(z.shape[0]*z.shape[1])\n",
    "                loss = loss_fn(pred, z)\n",
    "                pred_idx = torch.max(pred, 1)[1]\n",
    "                z_true_val += list(z.cpu().data.numpy())\n",
    "                z_pred_val += list(pred_idx.cpu().data.numpy())\n",
    "                total_loss_val += loss.item()\n",
    "                \n",
    "            valacc = accuracy_score(z_true_val, z_pred_val)\n",
    "            valloss = total_loss_val/len(val_dl)\n",
    "            print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {valloss:.4f} val_acc: {valacc:.4f}')\n",
    "        else:\n",
    "            print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f}')\n",
    "        total_val_loss.append(valloss)\n",
    "        total_val_acc.append(valacc)\n",
    "        \n",
    "        if valloss < prev_val_loss:\n",
    "            save_checkpoint(model, opt, \n",
    "                            total_train_loss,\n",
    "                            total_train_acc,\n",
    "                            total_val_loss,\n",
    "                            total_val_acc, \n",
    "                            lstm_model_file,\n",
    "                            epoch)\n",
    "            prev_val_loss = valloss\n",
    "            counter=0\n",
    "            print(\"This model saved!!!\")\n",
    "        else: \n",
    "            counter += 1\n",
    "            \n",
    "        if counter >= patience_limit: \n",
    "            print(\"Training stopped because maximum tolerance reached!!!\")\n",
    "            break\n",
    "            \n",
    "    return model, opt, total_train_loss, total_train_acc, total_val_loss, total_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, char_dim, batch_size, vocab_size, \n",
    "                 tagset_size, weights, one_hot_weight, bidirection=False, num_layers=1,\n",
    "                char_level=False, pos_level=False, graph_level=False):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.bidirectional = bidirection\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.char_embed_num = char_vocab_length\n",
    "        self.graph_embed_num = graph_vocab_length\n",
    "        self.char_dim = char_dim\n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(weights)\n",
    "        self.one_hot_embeddings = nn.Embedding(n_values, n_values, _weight=one_hot_weight)\n",
    "        self.char_embeddings = nn.Embedding(self.char_embed_num, self.char_dim, padding_idx=0)\n",
    "        self.graph_embeddings = nn.Embedding(self.graph_embed_num, self.char_dim, padding_idx=0)\n",
    "        self.char_level=char_level\n",
    "        self.pos_level=pos_level\n",
    "        self.graph_level=graph_level\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.char_embeddings.weight)\n",
    "        nn.init.xavier_uniform_(self.graph_embeddings.weight)\n",
    "        \n",
    "        self.rnn = nn.RNN(embedding_dim, self.hidden_dim, \n",
    "                            bidirectional=self.bidirectional, \n",
    "                            num_layers=self.num_layers)         \n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, self.hidden_dim, \n",
    "                            bidirectional=self.bidirectional, \n",
    "                            num_layers=self.num_layers)\n",
    "        if self.bidirectional:\n",
    "            self.hidden2tag = nn.Linear(self.hidden_dim * 2, tagset_size)\n",
    "        else:\n",
    "            self.hidden2tag = nn.Linear(self.hidden_dim * 2, tagset_size)      \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dropout_embed = nn.Dropout(0.5)\n",
    "        \n",
    "        self.linear1=nn.Linear(self.embedding_dim, self.hidden_dim)\n",
    "        self.linear2=nn.Linear(self.hidden_dim, tagset_size)\n",
    "        \n",
    "        #------------CNN\n",
    "        # Changed here for padding_idx error\n",
    "        self.conv_filter_sizes=[3,4,5]\n",
    "        self.conv_filter_nums=self.char_dim       # 30\n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = self.conv_filter_nums, \n",
    "                                              kernel_size = (fs, self.char_dim)) \n",
    "                                    for fs in self.conv_filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(self.conv_filter_sizes) * self.conv_filter_nums, self.char_dim)\n",
    "\n",
    "    def init_hidden(self, tensor_size):\n",
    "        if self.bidirectional:\n",
    "            h0 = torch.zeros(2 * self.num_layers, tensor_size[1], self.hidden_dim)\n",
    "            c0 = torch.zeros(2 * self.num_layers, tensor_size[1], self.hidden_dim)         \n",
    "        else:\n",
    "            h0 = torch.zeros(self.num_layers, tensor_size[1], self.hidden_dim)\n",
    "            c0 = torch.zeros(self.num_layers, tensor_size[1], self.hidden_dim)         \n",
    "        if device:\n",
    "            h0 = h0.to(device)\n",
    "            c0 = c0.to(device)\n",
    "        return (h0, c0)\n",
    "    \n",
    "    def get_char_tensor(self, X):\n",
    "        words=[]\n",
    "        for i in range(0, len(X)):\n",
    "            character=[]\n",
    "            char_int=[]\n",
    "            chunk = []\n",
    "            bigger_chunk = []\n",
    "            # For character-level\n",
    "            if self.char_level:\n",
    "                character+=\"\".join(str(x) for x in tensortosent(X[i]))\n",
    "                char_int+=(char_field.vocab.stoi[c] for c in character)\n",
    "            # For grapheme-level\n",
    "            else:\n",
    "                character+=[str(x) for x in grapheme_clusters(tensortosent(X[i]))]\n",
    "                char_int+=(graph_field.vocab.stoi[c] for c in character)\n",
    "            words.append(char_int)\n",
    "\n",
    "        # Get the max length of the words in a sentence\n",
    "        length = max(map(len, words))\n",
    "\n",
    "        # Padding to match the max_length words whose size is less than max(filter_size)\n",
    "        if length < max(self.conv_filter_sizes):\n",
    "            length += max(self.conv_filter_sizes) - length\n",
    "\n",
    "        # Zero-padding the unequal sentences\n",
    "        X_char=np.array([xi+[0]*(length-len(xi)) for xi in words])\n",
    "        X_char=torch.from_numpy(X_char)\n",
    "        \n",
    "        return X_char    \n",
    "    \n",
    "    \n",
    "    # ---------------------------------------CHARACTER FORWARD\n",
    "    def _char_forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: 3D tensor, [bs, max_len]\n",
    "        Returns:\n",
    "            char_conv_outputs: 3D tensor, [bs, max_len, output_dim]\n",
    "        \"\"\"\n",
    "        max_len = inputs.size(1)\n",
    "        inputs=inputs.to(device)\n",
    "        if self.char_level:\n",
    "            input_embed = self.char_embeddings(inputs)  # [bs, ml, feature_dim]\n",
    "        else:\n",
    "            input_embed=self.graph_embeddings(inputs)\n",
    "\n",
    "        # Since convolution is 2-dimension, we need 4 dimension tensor\n",
    "        input_embed = input_embed.unsqueeze(1)         # [bs, 1, max_len, feature_dim]\n",
    "                                                                 \n",
    "        # conv\n",
    "        conved = [F.relu(conv(input_embed)).squeeze(3) for conv in self.convs]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        return self.fc(cat)\n",
    "    \n",
    "    \n",
    "    def forward(self, X, y):\n",
    "#         print(\"Shape of X\", X.shape)\n",
    "        if self.char_level or self.graph_level:\n",
    "            # Get the X_char for each item in a batch here\n",
    "            # And concatenate in the end\n",
    "            # or do it insied get_char_tensor(X)\n",
    "            X_char=self.get_char_tensor(X)\n",
    "#             print(\"Shape of X_char\", X_char.shape)\n",
    "            \n",
    "        X = self.word_embeddings(X)\n",
    "        X = self.dropout_embed(X)\n",
    "\n",
    "        # Do the convolution here\n",
    "        if (self.char_level or self.graph_level):\n",
    "            char_conv = self._char_forward(X_char)\n",
    "            char_conv = char_conv.unsqueeze(1)\n",
    "#             print(\"Shape of char_conv\", char_conv.shape)            \n",
    "            X=torch.cat((X,char_conv), dim=-1)\n",
    "        \n",
    "        # Concatenate POS-embedding here\n",
    "        if self.pos_level:\n",
    "            POS = self.one_hot_embeddings(y)\n",
    "            X=torch.cat((X,POS), dim=-1)\n",
    "            \n",
    "        self.hidden = self.init_hidden(list(X.size()))\n",
    "        '''\n",
    "        This dropout was after LSTM layer, need to run experiment\n",
    "        and check result what happens, if it is kept before LSTM\n",
    "        All other researcher, have generally kept it before LSTM\n",
    "        '''\n",
    "        X = self.dropout(X)          \n",
    "        self.lstm.flatten_parameters()\n",
    "#         print(\"Shape of X before lstm\", X.shape)            \n",
    "        X, _ = self.lstm(X, self.hidden)  \n",
    "#         print(\"Shape of X after lstm\", X.shape)            \n",
    "#         self.rnn.flatten_parameters()   \n",
    "#         X, _ = self.rnn(X, self.hidden[0]) \n",
    "\n",
    "        X = torch.tanh(X)\n",
    "        tag_space = self.hidden2tag(X.view(-1, X.shape[2]))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONLY CHAR or GRAPHEME USED!!!!!!!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f213992feae545caae203615678b8e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=350), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss: 0.3981 train_acc: 0.9142 | val_loss: 0.3058 val_acc: 0.9090\n",
      "This model saved!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oyashi/miniconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTMTagger. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/oyashi/miniconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/oyashi/miniconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/oyashi/miniconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/oyashi/miniconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/oyashi/miniconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/oyashi/miniconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/oyashi/miniconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=350), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss: 0.2328 train_acc: 0.9304 | val_loss: 0.2310 val_acc: 0.9200\n",
      "This model saved!!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=350), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss: 0.1709 train_acc: 0.9351 | val_loss: 0.1803 val_acc: 0.9392\n",
      "This model saved!!!\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab_size = len(txt_field.vocab)\n",
    "CHAR_DIM = 30\n",
    "pos_level=False\n",
    "char_level=True\n",
    "graph_level=False\n",
    "EMBEDDING_DIM = vec.dim\n",
    "\n",
    "if (pos_level and (char_level or graph_level)):\n",
    "    assert(char_level != graph_level),\"Only one variable can be True at a time\"\n",
    "    print(\"POS AND CHAR/GRAPHEME BOTH USED!!!!!!!!\")\n",
    "    EMBEDDING_DIM += n_values + CHAR_DIM\n",
    "elif (char_level or graph_level):\n",
    "    assert(char_level != graph_level),\"Only one variable can be True at a time\"\n",
    "    print(\"ONLY CHAR or GRAPHEME USED!!!!!!!!\")\n",
    "    EMBEDDING_DIM += CHAR_DIM\n",
    "elif pos_level:\n",
    "    print(\"ONLY POS USED!!!!!!!!\")\n",
    "    EMBEDDING_DIM += n_values\n",
    "else:\n",
    "    print(\"NORMAL EMBEDDING USED!!!!!!!!\")\n",
    "\n",
    "HIDDEN_DIM=100\n",
    "tagset_size = len(label_field.vocab)\n",
    "batch_size=1\n",
    "weights = txt_field.vocab.vectors\n",
    "\n",
    "lstm_model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, CHAR_DIM, batch_size=batch_size,\n",
    "                        vocab_size=vocab_size, tagset_size=tagset_size,\n",
    "                        weights=weights,one_hot_weight=one_hot_weight,\n",
    "                        bidirection=True, num_layers=1, char_level=char_level,\n",
    "                       pos_level=pos_level, graph_level=graph_level).to(device)\n",
    "\n",
    "loss_func = nn.NLLLoss()\n",
    "\n",
    "opt = optim.Adam(filter(lambda p: p.requires_grad, lstm_model.parameters()), lr=0.001, weight_decay=0.000001)\n",
    "\n",
    "num_of_epochs=3\n",
    "\n",
    "train_iter, val_iter = data.BucketIterator.splits(datasets=(train_ds, val_ds), \n",
    "                                            batch_sizes=(batch_size, batch_size), \n",
    "                                            sort_key=lambda x: len(x.TEXT), \n",
    "                                            device=device, \n",
    "                                            sort_within_batch=True, \n",
    "                                            repeat=False,\n",
    "                                            shuffle=True)\n",
    "\n",
    "train_batch_it = BatchGenerator(train_iter, 'TEXT', 'POS', 'TAG')\n",
    "val_batch_it = BatchGenerator(val_iter, 'TEXT', 'POS', 'TAG')\n",
    "\n",
    "model_name='lstm'\n",
    "\n",
    "lstm_model_file = '../data/models/' + model_name + '.pth'\n",
    "\n",
    "if os.path.exists(lstm_model_file):\n",
    "    os.remove(lstm_model_file)\n",
    "\n",
    "if os.path.exists(lstm_model_file):\n",
    "    lstm_model, opt, lstm_train_loss, lstm_train_acc, lstm_val_loss, lstm_val_acc, epoch = load_checkpoint(lstm_model_file)\n",
    "\n",
    "    print(f'Epoch {epoch}: train_loss: {lstm_train_loss[-1]:.4f} train_acc: {lstm_train_acc[-1]:.4f} | val_loss: {lstm_val_loss[-1]:.4f} val_acc: {lstm_val_acc[-1]:.4f}')\n",
    "    # Resume training (Need to fix it)\n",
    "    if num_of_epochs > epoch:\n",
    "        lstm_model, opt, tmp_train_loss, tmp_train_acc, tmp_val_loss, tmp_val_acc = fit(model=lstm_model,\n",
    "                                                                                       train_dl=train_batch_it, \n",
    "                                                                                       val_dl=val_batch_it, \n",
    "                                                                                       loss_fn=loss_func, \n",
    "                                                                                       opt=opt,\n",
    "                                                                                       start_epoch=epoch,\n",
    "                                                                                       epochs=num_of_epochs)\n",
    "        lstm_train_loss += tmp_train_loss\n",
    "        lstm_train_acc += tmp_train_acc\n",
    "        lstm_val_loss += tmp_val_loss\n",
    "        lstm_val_acc += tmp_val_acc\n",
    "        \n",
    "        save_checkpoint(lstm_model, opt, \n",
    "                        lstm_train_loss,\n",
    "                        lstm_train_acc,\n",
    "                        lstm_val_loss,\n",
    "                        lstm_val_acc,\n",
    "                        lstm_model_file, \n",
    "                        num_of_epochs)\n",
    "\n",
    "else:\n",
    "    lstm_model, opt, lstm_train_loss, lstm_train_acc, lstm_val_loss, lstm_val_acc = fit(model=lstm_model,\n",
    "                                                                                        train_dl=train_batch_it,\n",
    "                                                                                        val_dl=val_batch_it,\n",
    "                                                                                        loss_fn=loss_func,\n",
    "                                                                                        opt=opt,\n",
    "                                                                                        start_epoch=0,\n",
    "                                                                                        lstm_model_file=lstm_model_file,\n",
    "                                                                                        epochs=num_of_epochs)\n",
    "#     save_checkpoint(lstm_model, opt, \n",
    "#                 lstm_train_loss,\n",
    "#                 lstm_train_acc,\n",
    "#                 lstm_val_loss,\n",
    "#                 lstm_val_acc,\n",
    "#                 lstm_model_file, \n",
    "#                 num_of_epochs)\n",
    "\n",
    "plot_loss(lstm_train_loss, lstm_val_loss, title='LSTM Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model!!!\n",
      "Writing in file:  ../data/ner/results/lstm_train.txt\n",
      "Writing in file:  ../data/ner/results/lstm_test.txt\n",
      "Writing in file:  ../data/ner/results/lstm_val.txt\n"
     ]
    }
   ],
   "source": [
    "def write_results(model, dataset, train_file, test_file, val_file):\n",
    "\n",
    "    train_iter, test_iter, val_iter = data.BucketIterator.splits(datasets=dataset, \n",
    "                                                batch_sizes=(1, 1, 1), \n",
    "                                                sort_key=lambda x: len(x.TEXT), \n",
    "                                                device=device, \n",
    "                                                sort_within_batch=True, \n",
    "                                                repeat=False,\n",
    "                                                shuffle=False)\n",
    "\n",
    "    train_batch_it = BatchGenerator(train_iter, 'TEXT', 'POS', 'TAG')\n",
    "    test_batch_it = BatchGenerator(test_iter, 'TEXT', 'POS', 'TAG')\n",
    "    val_batch_it = BatchGenerator(val_iter, 'TEXT', 'POS', 'TAG')\n",
    "\n",
    "    with open(train_file, 'w', encoding='utf-8') as rtrn:\n",
    "        model.eval()\n",
    "        print('Writing in file: ',train_file)\n",
    "        for ((X,y),z) in iter(train_batch_it):\n",
    "            sent = NumpyToSent(X)\n",
    "            pred = model(X,y)\n",
    "            pred_idx = torch.max(pred, 1)[1]\n",
    "\n",
    "            z = z.view(-1)\n",
    "            z_true_val = z.cpu().data.numpy().tolist()\n",
    "            true_tag = PredToTag(z_true_val)\n",
    "\n",
    "            z_pred_val = pred_idx.cpu().data.numpy().tolist()\n",
    "            pred_tag = PredToTag(z_pred_val)\n",
    "\n",
    "            for s, gt, pt in zip(sent, true_tag, pred_tag):\n",
    "                rtrn.write(s+' '+gt+' '+pt+'\\n')\n",
    "            rtrn.write('\\n')\n",
    "    rtrn.close()\n",
    "    \n",
    "    with open(test_file, 'w', encoding='utf-8') as rtst:\n",
    "        model.eval()\n",
    "        print('Writing in file: ',test_file)\n",
    "        for ((X,y),z) in iter(test_batch_it):\n",
    "            sent = NumpyToSent(X)\n",
    "            pred = model(X,y)\n",
    "            pred_idx = torch.max(pred, 1)[1]\n",
    "\n",
    "            z = z.view(-1)\n",
    "            z_true_val = z.cpu().data.numpy().tolist()\n",
    "            true_tag = PredToTag(z_true_val)\n",
    "\n",
    "            z_pred_val = pred_idx.cpu().data.numpy().tolist()\n",
    "            pred_tag = PredToTag(z_pred_val)\n",
    "\n",
    "            for s, gt, pt in zip(sent, true_tag, pred_tag):\n",
    "                rtst.write(s+' '+gt+' '+pt+'\\n')\n",
    "            rtst.write('\\n')\n",
    "    rtst.close()\n",
    "    \n",
    "    with open(val_file, 'w', encoding='utf-8') as rval:\n",
    "        model.eval()\n",
    "        print('Writing in file: ',val_file)\n",
    "        for ((X,y),z) in iter(val_batch_it):\n",
    "            sent = NumpyToSent(X)\n",
    "            pred = model(X,y)\n",
    "            pred_idx = torch.max(pred, 1)[1]\n",
    "\n",
    "            z = z.view(-1)\n",
    "            z_true_val = z.cpu().data.numpy().tolist()\n",
    "            true_tag = PredToTag(z_true_val)\n",
    "\n",
    "            z_pred_val = pred_idx.cpu().data.numpy().tolist()\n",
    "            pred_tag = PredToTag(z_pred_val)\n",
    "\n",
    "            for s, gt, pt in zip(sent, true_tag, pred_tag):\n",
    "                rval.write(s+' '+gt+' '+pt+'\\n')\n",
    "            rval.write('\\n')\n",
    "    rval.close()    \n",
    "\n",
    "file_train=model_name +'_train.txt'\n",
    "file_test=model_name +'_test.txt'\n",
    "file_val=model_name +'_val.txt'\n",
    "\n",
    "result_train = '../data/ner/results/' + file_train\n",
    "result_test = '../data/ner/results/' + file_test\n",
    "result_val = '../data/ner/results/' + file_val\n",
    "\n",
    "load_best_model=True\n",
    "if load_best_model:\n",
    "    print(\"Loading best model!!!\")\n",
    "    lstm_model, opt, lstm_train_loss, lstm_train_acc, lstm_val_loss, lstm_val_acc, epoch = load_checkpoint(lstm_model_file)\n",
    "\n",
    "write_results(model=lstm_model, dataset=(train_ds, test_ds, val_ds), \n",
    "              train_file=result_train,\n",
    "              test_file=result_test, \n",
    "              val_file=result_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 9014 tokens with 471 phrases; found: 489 phrases; correct: 432.\n",
      "accuracy:  96.37%; (non-O)\n",
      "accuracy:  99.13%; precision:  88.34%; recall:  91.72%; FB1:  90.00\n",
      "              LOC: precision:  93.02%; recall:  96.77%; FB1:  94.86  129\n",
      "             MISC: precision:  86.54%; recall:  94.74%; FB1:  90.45  208\n",
      "              ORG: precision:  74.51%; recall:  79.17%; FB1:  76.77  51\n",
      "              PER: precision:  93.07%; recall:  86.24%; FB1:  89.52  101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(96.36608344549126, 88.34355828220859, 91.71974522292994, 90.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    These are NOT actual CONLL evaluation\n",
    "    You need to run separately\n",
    "\"\"\"\n",
    "e.evaluate_conll_file(result_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 3116 tokens with 143 phrases; found: 144 phrases; correct: 106.\n",
      "accuracy:  79.53%; (non-O)\n",
      "accuracy:  97.75%; precision:  73.61%; recall:  74.13%; FB1:  73.87\n",
      "              LOC: precision:  82.46%; recall:  75.81%; FB1:  78.99  57\n",
      "             MISC: precision:  70.00%; recall:  85.71%; FB1:  77.06  60\n",
      "              ORG: precision:  50.00%; recall:  60.00%; FB1:  54.55  6\n",
      "              PER: precision:  66.67%; recall:  51.85%; FB1:  58.33  21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(79.53488372093024, 73.61111111111111, 74.12587412587412, 73.86759581881532)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.evaluate_conll_file(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 2279 tokens with 132 phrases; found: 138 phrases; correct: 101.\n",
      "accuracy:  79.73%; (non-O)\n",
      "accuracy:  97.19%; precision:  73.19%; recall:  76.52%; FB1:  74.81\n",
      "              LOC: precision:  72.50%; recall:  82.86%; FB1:  77.33  40\n",
      "             MISC: precision:  85.96%; recall:  89.09%; FB1:  87.50  57\n",
      "              ORG: precision:  16.67%; recall:  18.18%; FB1:  17.39  12\n",
      "              PER: precision:  72.41%; recall:  67.74%; FB1:  70.00  29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(79.72972972972973, 73.18840579710145, 76.51515151515152, 74.81481481481481)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.evaluate_conll_file(result_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print('Completed everything')\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_truth_pred(fileName):\n",
    "    true_seqs, pred_seqs = [], []\n",
    "    \n",
    "    with open(fileName, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            cols = line.strip().split()\n",
    "            # each non-empty line must contain >= 3 columns\n",
    "            if not cols:\n",
    "                true_seqs.append('O')\n",
    "                pred_seqs.append('O')\n",
    "            elif len(cols) < 3:\n",
    "                raise IOError(\"conlleval: too few columns in line %s\\n\" % line)\n",
    "            else:\n",
    "                # extract tags from last 2 columns\n",
    "                true_seqs.append(cols[-2])\n",
    "                pred_seqs.append(cols[-1])\n",
    "    return true_seqs, pred_seqs\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def display_confusion_matrix(filename, title):\n",
    "    y_true, y_pred = get_truth_pred(filename)\n",
    "    labels=[\"B-PER\", \"B-LOC\", \"B-ORG\", \"B-MISC\", \"I-PER\", \"I-LOC\", \"I-ORG\", \"I-MISC\", \"O\", \"<pad>\"]\n",
    "    labels=[\"PER\", \"LOC\", \"ORG\", \"MISC\", \"O\", \"<pad>\"]\n",
    "    \n",
    "#     tag_dict = {\"B-PER\": 0, \"B-LOC\": 1, \"B-ORG\": 2, \"B-MISC\" : 3, \"I-PER\": 4, \"I-LOC\": 5, \"I-ORG\": 6, \"I-MISC\":7, \"O\": 8, '<pad>':9}\n",
    "    tag_dict = {\"PER\": 0, \"LOC\": 1, \"ORG\": 2, \"MISC\" : 3, \"O\": 4, '<pad>':5}\n",
    "\n",
    "    y_true_final = list(map(tag_dict.get, y_true))\n",
    "    y_pred_final = list(map(tag_dict.get, y_pred))\n",
    "\n",
    "    plot_confusion_matrix(y_true_final, y_pred_final, classes=labels, normalize=False, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_confusion_matrix(result_train, 'Confusion matrix on train data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_confusion_matrix(result_test, 'Confusion matrix on test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_confusion_matrix(result_val, 'Confusion matrix on val data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 999\n",
    "'''\n",
    "    Get the TP/FP/FN based on PER/ORG/LOC TAG only\n",
    "'''\n",
    "def get_stats(src_file, dest_file):\n",
    "    df = pd.read_csv(src_file, delimiter=' ', encoding='utf-8', skip_blank_lines=True, quoting=csv.QUOTE_NONE, header=None, names=['TEXT', 'GT', 'PT'])\n",
    "    entity_df = df[(df.PT == 'ORG') | (df.PT == 'PER') | (df.PT == 'LOC') | (df.GT == 'ORG') | (df.GT == 'PER') | (df.GT == 'LOC') | (df.GT == 'MISC') | (df.PT == 'MISC')].reset_index(drop=True)\n",
    "    \n",
    "    num_of_words = len(entity_df)\n",
    "\n",
    "    acc_df = entity_df[entity_df.GT == entity_df.PT].reset_index(drop=True)\n",
    "\n",
    "    org_tp = acc_df[acc_df.GT == 'ORG'].reset_index(drop=True)\n",
    "    org_tp['COMMENTS']='ORG_TP'\n",
    "    per_tp = acc_df[acc_df.GT == 'PER'].reset_index(drop=True)\n",
    "    per_tp['COMMENTS']='PER_TP'\n",
    "    loc_tp = acc_df[acc_df.GT == 'LOC'].reset_index(drop=True)\n",
    "    loc_tp['COMMENTS']='LOC_TP'\n",
    "    misc_tp = acc_df[acc_df.GT == 'MISC'].reset_index(drop=True)\n",
    "    misc_tp['COMMENTS']='MISC_TP'\n",
    "\n",
    "    org_fn = entity_df[(entity_df.GT == 'ORG') & (entity_df.PT != 'ORG')].reset_index(drop=True)\n",
    "    org_fn['COMMENTS']='ORG_FN'\n",
    "    per_fn = entity_df[(entity_df.GT == 'PER') & (entity_df.PT != 'PER')].reset_index(drop=True)\n",
    "    per_fn['COMMENTS']='PER_FN'\n",
    "    loc_fn = entity_df[(entity_df.GT == 'LOC') & (entity_df.PT != 'LOC')].reset_index(drop=True)\n",
    "    loc_fn['COMMENTS']='LOC_FN'\n",
    "    misc_fn = entity_df[(entity_df.GT == 'MISC') & (entity_df.PT != 'MISC')].reset_index(drop=True)\n",
    "    misc_fn['COMMENTS']='MISC_FN'    \n",
    "\n",
    "    org_fp = entity_df[(entity_df.PT == 'ORG') & (entity_df.GT != 'ORG')].reset_index(drop=True)\n",
    "    org_fp['COMMENTS']='ORG_FP'\n",
    "    per_fp = entity_df[(entity_df.PT == 'PER') & (entity_df.GT != 'PER')].reset_index(drop=True)\n",
    "    per_fp['COMMENTS']='PER_FP'\n",
    "    loc_fp = entity_df[(entity_df.PT == 'LOC') & (entity_df.GT != 'LOC')].reset_index(drop=True)\n",
    "    loc_fp['COMMENTS']='LOC_FP'\n",
    "    misc_fp = entity_df[(entity_df.PT == 'MISC') & (entity_df.GT != 'MISC')].reset_index(drop=True)\n",
    "    misc_fp['COMMENTS']='MISC_FP'    \n",
    "    \n",
    "    final_df=pd.concat([org_tp, per_tp, loc_tp, misc_tp, org_fn, per_fn, loc_fn, misc_fn, org_fp, per_fp, loc_fp, misc_fp], ignore_index=True)\n",
    "    final_df.to_csv(dest_file, sep='\\t',encoding='utf-8',index=False,header=True)\n",
    "    return final_df\n",
    "\n",
    "file=file_train\n",
    "root='../data/ner/results/'\n",
    "source_file = root+file\n",
    "dest_file=root+'stat_'+file\n",
    "result_df=get_stats(source_file, dest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[(result_df.COMMENTS=='LOC_FN')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df=result_df[result_df.COMMENTS=='ORG_FN']\n",
    "\n",
    "list_text=list(count_df.TEXT.values)\n",
    "\n",
    "import collections\n",
    "counter=collections.Counter(list_text)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
